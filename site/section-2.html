<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>What&rsquo;s an Agent, Anyway? — Agent SDKs for the Rest of Us</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body class="content-page">

    <aside class="sidebar">
        <div class="sidebar-header">
            <span class="mono-label sidebar-header__label">Report</span>
            <h1 class="sidebar-header__title"><a href="index.html">Agent SDKs for the Rest of Us</a></h1>
        </div>
        <nav class="sidebar-nav">
            <a href="section-1.html" class="nav-item">
                <span class="nav-num">01</span>
                <span class="nav-title">Mapping the Terrain</span>
            </a>
            <a href="section-2.html" class="nav-item active">
                <span class="nav-num">02</span>
                <span class="nav-title">What's an Agent, Anyway?</span>
            </a>
            <a href="section-3.html" class="nav-item">
                <span class="nav-num">03</span>
                <span class="nav-title">Where Orchestration Lives</span>
            </a>
            <a href="section-4.html" class="nav-item">
                <span class="nav-num">04</span>
                <span class="nav-title">Two Tools to Rule Them All</span>
            </a>
            <a href="section-5.html" class="nav-item">
                <span class="nav-num">05</span>
                <span class="nav-title">Agent SDK to Agent Server</span>
            </a>
            <a href="section-6.html" class="nav-item">
                <span class="nav-num">06</span>
                <span class="nav-title">Architecture by Example</span>
            </a>
            <a href="section-7.html" class="nav-item">
                <span class="nav-num">07</span>
                <span class="nav-title">Further Reading</span>
            </a>
        </nav>
    </aside>

    <main class="content-main">
        <div class="top-bar">
            <div class="top-bar__meta">
                <div class="meta-item">
                    <span class="mono-label">Subject</span>
                    <span class="meta-item__value">Agent Frameworks</span>
                </div>
                <div class="meta-item">
                    <span class="mono-label">Date</span>
                    <span class="meta-item__value">Feb 2026</span>
                </div>
            </div>
            <div class="meta-item">
                <span class="mono-label">Section</span>
                <span class="meta-item__value">02 / 07</span>
            </div>
        </div>

        <div class="content-body">
            <div class="content-body__section-num">02</div>
            <h1 class="content-body__title">What&rsquo;s an Agent, Anyway?</h1>

<p><strong>An agent is an LLM running tools in a loop</strong>:</p>
<ul>
<li><a href="https://simonwillison.net/2025/Sep/18/agents/">Simon Willison</a>&#39;s one-liner — &quot;An LLM agent runs tools in a loop to achieve a goal&quot; — has become the closest thing to a consensus definition.</li>
<li><a href="https://blog.langchain.com/deep-agents/">Harrison Chase</a> (LangChain) said the same thing differently: &quot;The core algorithm is actually the same — it&#39;s an LLM running in a loop calling tools.&quot;</li>
</ul>
<p><strong>So an agent has 3 ingredients</strong>:</p>
<ul>
<li>An LLM</li>
<li>Tools</li>
<li>A loop.</li>
</ul>
<p>Let&#39;s unpack each one.</p>
<h2>What an LLM does</h2>
<p><strong>An LLM is a text-completion machine.</strong> You send it a chain of characters. It predicts the next most probable character, then the next, until it stops.</p>
<p>When you ask a question, the sequence of most probable next characters is likely to be a sentence that resembles an answer to your question.</p>
<p><strong>An LLM can only produce text.</strong> It cannot browse the web. It cannot run a calculation using a program. It cannot read a file or call an API.</p>
<h2>What a tool is</h2>
<p>A tool gives an LLM capabilities it does not have natively. Tools enable:</p>
<ul>
<li><strong>Things LLM cannot do:</strong> access the internet, query a database, execute code.</li>
<li><strong>Things LLM do badly:</strong> arithmetic, find exact-matches in a document...</li>
</ul>
<p><strong>The LLM cannot execute tools on its own though:</strong></p>
<ul>
<li>It can return text that matches a demand for tool-calling.</li>
<li>The tool must be run by the program calling the LLM.</li>
<li>And the result must be passed by the program back to the LLM.</li>
</ul>
<h2>How LLMs learned to call tools</h2>
<p>We said that an LLM can only produce text. So how does it ask for calling a tool? Does it return a text saying &quot;I need to run the calculator&quot; or something like that?</p>
<p><strong>To call a tool, the LLM returns a JSON object</strong> that says which tool it wants to run, and with which parameters.</p>
<p>For example, if the LLM wants to check the weather in Paris, instead of responding with text, it returns something like:</p>
<pre><code class="language-json">{
  &quot;type&quot;: &quot;tool_use&quot;,
  &quot;name&quot;: &quot;get_weather&quot;,
  &quot;input&quot;: { &quot;city&quot;: &quot;Paris&quot; }
}
</code></pre>
<p>But how did the LLM learn to generate such JSON objects as the <em>most likely chain of characters</em> in the middle of a conversation in plain English?</p>
<p><strong>Tool calling is not something that existed in the original training data.</strong> Nobody writes &quot;output a JSON object to invoke a calculator function&quot; on the internet.</p>
<p><strong>LLMs are specifically trained to learn when to use tools</strong> through fine-tuning on tool-use transcripts:</p>
<ul>
<li>The models are trained on many examples of conversations where the assistant produces structured function invocations, receives results, and continues. OpenAI shipped this first commercially (June 2023, GPT-3.5/GPT-4), and other providers followed.</li>
<li>The model does not learn each specific tool. It learns the <em>general pattern</em>: when to invoke, how to format the call, how to integrate the result.</li>
<li>The specific tools available are described in the prompt — the model reads their names, descriptions, and parameter schemas as text.</li>
</ul>
<p><strong>Tool hallucination is a consequence of tool training.</strong> The model can generate calls to tools that were never provided, or fabricate parameters. UC Berkeley&#39;s <a href="https://gorilla.cs.berkeley.edu/">Gorilla project</a> (Berkeley Function-Calling Leaderboard) has documented this systematically — it is one reason agent frameworks invest in validation and error handling.</p>
<h2>The two-step pattern</h2>
<p><strong>When you call an LLM with tools enabled, two things can happen:</strong></p>
<ol>
<li>The model responds with <strong>text</strong> — it has enough information to answer directly.</li>
<li>The model responds with a <strong>tool-call request</strong> — a structured object specifying which tool to call and what arguments to pass.</li>
</ol>
<p>If the model requests a tool call, <em>your code</em> executes it. You send the result back as a follow-up message. The model uses that result to formulate its answer — or to request yet another tool call.</p>
<p><strong>Tool use always involves at least two model calls.</strong>:</p>
<ul>
<li>The first model call returns a tool call request</li>
<li>The second model call is provided the conversation + the result of the tool call.</li>
</ul>
<pre><code>messages = [system_prompt, user_message]

# LLM Call 1 — send the conversation + list of available tools
response = llm(messages, tools=available_tools)

# Did the model respond with text, or with a tool-call request?
if response.has_tool_call:
    tool_call = response.tool_call
    result = execute(tool_call.name, tool_call.arguments)
    messages.append(tool_call)
    messages.append(tool_result(tool_call.id, result))

    # LLM Call 2 — send the conversation again, now including the tool result
    response = llm(messages, tools=available_tools)
</code></pre>
<h2>The agentic loop</h2>
<p><strong>Many tasks require more than one tool call.</strong> A coding assistant might read a file, edit it, run the tests, check output, fix a failing test — all in sequence. The model cannot know in advance how many steps it will need.</p>
<p><strong>The solution: wrap the two-step pattern in a loop.</strong></p>
<pre><code>messages = [system_prompt, user_message]

loop:
    response = llm(messages, tools=available_tools)

    if response.has_tool_calls:
        for call in response.tool_calls:
            result = execute(call.name, call.arguments)
            messages.append(call)
            messages.append(tool_result(call.id, result))
        continue

    break  # no tool calls — done

print(response.text)
</code></pre>
<p><strong>The model loops:</strong> calling tools, receiving results, deciding what to do next, until it produces text instead of another tool call.</p>
<p><strong>In practice, you add guardrails:</strong> a maximum number of iterations, a cost budget, validation checks. But the core mechanism is the same.</p>
<p><strong>What this looks like in practice.</strong> Here is a simplified trace of an agent booking a restaurant. Each block is one iteration of the loop:</p>
<pre><code>User:      &quot;Find me a good Italian restaurant near the office
            for Friday dinner, 4 people.&quot;

Agent:     [tool: search_web(&quot;Italian restaurants near 123 Main St&quot;)]
           → 3 results: Trattoria Roma, Pasta House, Il Giardino

Agent:     [tool: get_reviews(&quot;Trattoria Roma&quot;, &quot;Pasta House&quot;, &quot;Il Giardino&quot;)]
           → Trattoria Roma: 4.7★, Pasta House: 3.9★, Il Giardino: 4.5★

Agent:     [tool: check_availability(&quot;Trattoria Roma&quot;, friday, party=4)]
           → available at 7:30 PM and 8:00 PM

Agent:     &quot;Trattoria Roma is the best rated (4.7★) and has two
            slots Friday for 4: 7:30 PM or 8:00 PM.
            Want me to book one?&quot;
</code></pre>
<p><strong>Four loop iterations.</strong> Three tool calls, then a text response that ends the loop. The agent decided which restaurants to look up, which one to check availability for first (the highest rated), and when it had enough information to stop. The program just ran the tools and passed results back.</p>
<h2>What to keep in mind</h2>
<ul>
<li><strong>An agent is an LLM + tools + a loop.</strong> Every agent framework — PydanticAI, LangGraph, Claude Agent SDK, OpenAI Agents SDK — implements some version of this loop. They differ in what they build <em>around</em> it.</li>
<li><strong>Tool calling is a two-step pattern.</strong> The model requests, your code executes, the result feeds back. This is important because it means someone has to <em>run</em> those tools — and where that happens is an architectural decision.</li>
<li><strong>The model decides when to stop.</strong> In the simplest case, it stops when it produces text instead of a tool call. But in real systems, stop conditions are a design surface: budgets, validation, user acceptance, timeouts.</li>
</ul>

        </div>
    </main>

</body>
</html>
